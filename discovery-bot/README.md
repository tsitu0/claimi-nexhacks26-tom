# Claimi - Settlement Discovery Agent

An edge-deployed multi-agent system that discovers settlements, parses eligibility into verifiable rules with citations, and stores structured data for downstream processing.

## ğŸ¯ What It Does

**Agent 1: Settlement Intake Agent (Parser)**

Takes a settlement URL and produces structured eligibility data:

```json
{
  "title": "Example Class Action Settlement",
  "deadline": "2026-03-01",
  "eligibility_rules": {
    "locations": {"include": ["US"], "exclude": ["CA"]},
    "date_range": {"start": "2021-01-01", "end": "2023-12-31"},
    "requirements": ["had an account", "purchased product X"],
    "proof": {"required": false, "examples": ["receipt", "account screenshot"]}
  },
  "citations": [
    {"quote": "Eligible if you purchased...", "source_url": "...", "section": "Eligibility"}
  ],
  "claim_url": "https://..."
}
```

âœ… **Citations** â†’ Judges and users love seeing exact source quotes for trust

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
npm install
```

### 2. Set Up Environment Variables

Create a `.env` file in the project root:

```bash
# Supabase (required for storage)
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_ANON_KEY=your-anon-key

# OpenAI (required for LLM parsing)
OPENAI_API_KEY=sk-your-openai-key

# LeanMCP (for deployment)
LEANMCP_API_KEY=leanmcp_your-key

# Optional
PORT=3000
```

### 3. Set Up Supabase Database

Run this SQL in your Supabase SQL Editor:

```sql
-- Create settlements table
CREATE TABLE IF NOT EXISTS settlements (
  id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  title TEXT NOT NULL,
  deadline DATE,
  eligibility_rules JSONB NOT NULL DEFAULT '{}',
  citations JSONB NOT NULL DEFAULT '[]',
  claim_url TEXT,
  source_url TEXT UNIQUE NOT NULL,
  raw_content TEXT,
  status TEXT NOT NULL DEFAULT 'discovered',
  created_at TIMESTAMPTZ DEFAULT NOW(),
  updated_at TIMESTAMPTZ DEFAULT NOW()
);

-- Create indexes
CREATE INDEX IF NOT EXISTS idx_settlements_source_url ON settlements(source_url);
CREATE INDEX IF NOT EXISTS idx_settlements_status ON settlements(status);
CREATE INDEX IF NOT EXISTS idx_settlements_deadline ON settlements(deadline);

-- Enable RLS
ALTER TABLE settlements ENABLE ROW LEVEL SECURITY;

-- Allow all operations (adjust for your auth needs)
CREATE POLICY "Allow all operations" ON settlements
  FOR ALL USING (true) WITH CHECK (true);
```

### 4. Run the Server

```bash
# Development
npm run dev

# Production
npm run build
npm start
```

## ğŸ“¡ API Endpoints

| Endpoint | Description |
|----------|-------------|
| `POST /mcp` | MCP protocol endpoint (JSON-RPC 2.0) |
| `GET /health` | Health check |
| `GET /` | Dashboard |

## ğŸ”§ Available Tools

### `discoverSettlement`
Scrape and parse a single settlement URL.

**Input:**
```json
{
  "url": "https://www.settlementwebsite.com/case-page"
}
```

**Output:**
```json
{
  "success": true,
  "settlement": {
    "title": "...",
    "deadline": "2026-03-01",
    "eligibility_rules": {...},
    "citations": [...],
    "claim_url": "..."
  }
}
```

### `batchDiscoverSettlements`
Process multiple settlement URLs at once.

**Input:**
```json
{
  "urls": [
    "https://settlement1.com",
    "https://settlement2.com"
  ]
}
```

### `getSettlement`
Retrieve a settlement by ID.

**Input:**
```json
{
  "id": "uuid-here"
}
```

### `listSettlements`
List all discovered settlements.

**Input:**
```json
{
  "status": "discovered"  // optional: discovered, parsed, verified, expired
}
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    MCP Client (AI Agent)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   LeanMCP Server (:3000)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚               Discovery Service (MCP)                   â”‚â”‚
â”‚  â”‚  â€¢ discoverSettlement                                   â”‚â”‚
â”‚  â”‚  â€¢ batchDiscoverSettlements                             â”‚â”‚
â”‚  â”‚  â€¢ getSettlement / listSettlements                      â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
          â–¼                   â–¼                   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Web Scraper    â”‚ â”‚   LLM Parser     â”‚ â”‚    Supabase      â”‚
â”‚  (Cheerio/Axios) â”‚ â”‚   (GPT-4o)       â”‚ â”‚   (Storage)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
claimi-nexhacks26/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ agents/
â”‚   â”‚   â””â”€â”€ settlement-intake.ts   # Main discovery agent
â”‚   â”œâ”€â”€ tools/
â”‚   â”‚   â””â”€â”€ scraper.ts             # Web scraping utilities
â”‚   â”œâ”€â”€ lib/
â”‚   â”‚   â””â”€â”€ supabase.ts            # Supabase client
â”‚   â”œâ”€â”€ types/
â”‚   â”‚   â””â”€â”€ settlement.ts          # TypeScript types
â”‚   â”œâ”€â”€ config.ts                  # Configuration
â”‚   â””â”€â”€ server.ts                  # Main server
â”œâ”€â”€ mcp/
â”‚   â””â”€â”€ discovery/
â”‚       â””â”€â”€ index.ts               # MCP Discovery Service
â”œâ”€â”€ package.json
â””â”€â”€ tsconfig.json
```

## ğŸ” Security Notes

- API keys are stored in environment variables
- Never commit `.env` file to version control
- Supabase RLS policies should be configured for production
- Rate limit scraping to be respectful of source sites

## ğŸš¢ Deployment

### Deploy to LeanMCP Platform

```bash
npm run leanmcp:login
npm run leanmcp:deploy
```

### Self-Hosted

Build and deploy the `dist/` folder to any Node.js hosting platform (Vercel, Railway, Fly.io, etc.)

## ğŸ§ª Testing a Settlement URL

```bash
# Start the server
npm run dev

# In another terminal, test with curl
curl -X POST http://localhost:3000/mcp \
  -H "Content-Type: application/json" \
  -d '{
    "jsonrpc": "2.0",
    "method": "tools/call",
    "params": {
      "name": "discoverSettlement",
      "arguments": {
        "url": "https://www.topclassactions.com/example-settlement"
      }
    },
    "id": 1
  }'
```

## ğŸ“š Resources

- [LeanMCP Documentation](https://docs.leanmcp.com)
- [Model Context Protocol](https://modelcontextprotocol.io)
- [Supabase Docs](https://supabase.com/docs)

## ğŸ“ License

ISC
